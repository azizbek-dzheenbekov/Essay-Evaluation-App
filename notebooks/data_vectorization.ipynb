{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization (TF-IDF vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_{|}~'\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in punctuation]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "data['full_text_wo_punct'] = data['full_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['full_text_wo_punct'] = data['full_text_wo_punct'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 4996)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(2,4), max_df = 0.8, min_df = 50)\n",
    "\n",
    "tfidf_matrix = tfidf_vect.fit_transform(data['full_text_wo_punct'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['full_text_wo_punct'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_data = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data = pd.concat([data, tf_idf_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 5016)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>excl_quest_sign_count</th>\n",
       "      <th>contractions_count</th>\n",
       "      <th>...</th>\n",
       "      <th>your time</th>\n",
       "      <th>your way</th>\n",
       "      <th>your work</th>\n",
       "      <th>yourself and</th>\n",
       "      <th>yourself in</th>\n",
       "      <th>yourself in world</th>\n",
       "      <th>yourself in world that</th>\n",
       "      <th>yourself is</th>\n",
       "      <th>yourself to</th>\n",
       "      <th>yourself you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal If u change the school policy ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138985</td>\n",
       "      <td>0.077777</td>\n",
       "      <td>0.081278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal If u change the school policy ...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0   \n",
       "1     2.5         3.0          2.0      2.0          2.5   \n",
       "2     3.5         3.0          3.0      3.0          2.5   \n",
       "3     4.5         4.5          4.5      4.0          5.0   \n",
       "4     3.0         3.0          3.0      2.5          2.5   \n",
       "\n",
       "   excl_quest_sign_count  contractions_count  ...  your time  your way  \\\n",
       "0                      0                  16  ...        0.0       0.0   \n",
       "1                      0                  17  ...        0.0       0.0   \n",
       "2                      0                  21  ...        0.0       0.0   \n",
       "3                      0                  54  ...        0.0       0.0   \n",
       "4                      0                   3  ...        0.0       0.0   \n",
       "\n",
       "   your work yourself and  yourself in  yourself in world  \\\n",
       "0        0.0          0.0     0.000000           0.000000   \n",
       "1        0.0          0.0     0.000000           0.000000   \n",
       "2        0.0          0.0     0.000000           0.000000   \n",
       "3        0.0          0.0     0.138985           0.077777   \n",
       "4        0.0          0.0     0.000000           0.000000   \n",
       "\n",
       "   yourself in world that  yourself is  yourself to  yourself you  \n",
       "0                0.000000          0.0          0.0           0.0  \n",
       "1                0.000000          0.0          0.0           0.0  \n",
       "2                0.000000          0.0          0.0           0.0  \n",
       "3                0.081278          0.0          0.0           0.0  \n",
       "4                0.000000          0.0          0.0           0.0  \n",
       "\n",
       "[5 rows x 5016 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data.to_csv('../data/tf_idf_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_vectorize(data):\n",
    "    tfidf_vect = TfidfVectorizer(ngram_range=(1,3), max_df = 0.8, min_df = 3)\n",
    "    tfidf_matrix = tfidf_vect.fit_transform(data['full_text_wo_punct'])\n",
    "\n",
    "    tf_idf_data = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=tfidf_vect.get_feature_names_out())\n",
    "    tf_idf_data = pd.merge(data, tf_idf_data, left_index=True, right_index=True)\n",
    "\n",
    "    return tf_idf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization (Min Max Scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = ['cohesion', 'syntax', 'vocabulary','phraseology', \n",
    "           'grammar', 'conventions', 'excl_quest_sign_count',\n",
    "           'contractions_count', 'capitalized_mistakes', \n",
    "           'word_count', 'sentence_count', 'paragraph_count',\n",
    "           'avg_word_count_per_paragraph', 'avg_sentence_count_per_paragraph',\n",
    "           'has_short_paragraphs', 'difficult_word_count',\n",
    "           'spelling_mistake_count']\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[columns])\n",
    "\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=columns)\n",
    "scaled_data = pd.merge(data[['text_id', 'full_text', 'paragraphs']], scaled_data, left_index=True, right_index=True)\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(feature_data):\n",
    "    columns = ['cohesion', 'syntax', 'vocabulary','phraseology', \n",
    "            'grammar', 'conventions', 'excl_quest_sign_count',\n",
    "            'contractions_count', 'capitalized_mistakes', \n",
    "            'word_count', 'sentence_count', 'paragraph_count',\n",
    "            'avg_word_count_per_paragraph', 'avg_sentence_count_per_paragraph',\n",
    "            'has_short_paragraphs', 'difficult_word_count',\n",
    "            'spelling_mistake_count']\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(feature_data[columns])\n",
    "\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=columns)\n",
    "    scaled_data = pd.merge(feature_data[['text_id', 'full_text', 'paragraphs']], scaled_data, left_index=True, right_index=True)\n",
    "    \n",
    "    return scaled_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('internship')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9981a89fe2c9ec0ec59c5446404d33ee1517d9667a8d5d65e49d83bb83ea2f95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
